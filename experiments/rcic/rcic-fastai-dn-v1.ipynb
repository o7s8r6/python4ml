{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uggxhoHpwa2K"
   },
   "source": [
    "# Recursion Cellular Image Classification - Densenet \n",
    "\n",
    "Thanks greatly to [this kaggle kernel](https://www.kaggle.com/kernels/scriptcontent/20557703/download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m67AVgPxwa2L"
   },
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92p63IbDwa2L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU cuda:\t True\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU cuda:\\t\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn save name rcic-dn121-sz448-bs26-s1\n"
     ]
    }
   ],
   "source": [
    "SIZE = 448\n",
    "SITE = 1\n",
    "BS = 26\n",
    "MODEL_TYPE = \"dn121\"\n",
    "LOAD = False\n",
    "LOAD_NAME = \"rcic____\"\n",
    "SAVE_NAME = \"rcic-%s-sz%s-bs%s-s%s\"%(MODEL_TYPE,SIZE,BS,SITE)+\"\"\n",
    "print(\"learn save name\",SAVE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mJopzu_evYF"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAHj2Ulawa2R"
   },
   "source": [
    "## Loading and formatting data\n",
    "\n",
    "Here I will load the csv into the DataFrame, and create a column in the DataFrame with the path to the corresponding image (`generate_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataframe\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(\"Loading training dataframe\")\n",
    "DATA = Path(\"/mnt/disk4/cell/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "VI6_C0cVwa2R",
    "outputId": "64557492-946d-4cd1-9a7a-087edc91886d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>experiment</th>\n",
       "      <th>plate</th>\n",
       "      <th>well</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HEPG2-01_1_B03</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B03</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HEPG2-01_1_B04</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B04</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HEPG2-01_1_B05</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B05</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HEPG2-01_1_B06</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B06</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HEPG2-01_1_B07</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B07</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>HEPG2-01_1_B08</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B08</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>HEPG2-01_1_B09</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B09</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>HEPG2-01_1_B10</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B10</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>HEPG2-01_1_B11</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B11</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>HEPG2-01_1_B12</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code experiment  plate well  sirna\n",
       "0  HEPG2-01_1_B03   HEPG2-01      1  B03    513\n",
       "1  HEPG2-01_1_B04   HEPG2-01      1  B04    840\n",
       "2  HEPG2-01_1_B05   HEPG2-01      1  B05   1020\n",
       "3  HEPG2-01_1_B06   HEPG2-01      1  B06    254\n",
       "4  HEPG2-01_1_B07   HEPG2-01      1  B07    144\n",
       "5  HEPG2-01_1_B08   HEPG2-01      1  B08    503\n",
       "6  HEPG2-01_1_B09   HEPG2-01      1  B09    188\n",
       "7  HEPG2-01_1_B10   HEPG2-01      1  B10    700\n",
       "8  HEPG2-01_1_B11   HEPG2-01      1  B11   1100\n",
       "9  HEPG2-01_1_B12   HEPG2-01      1  B12    611"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(DATA/'train.csv')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeEIRS-iwa2T"
   },
   "outputs": [],
   "source": [
    "def generate_df(train_df,sample_num=1):\n",
    "    train_df['path'] = train_df['experiment'].str.cat(train_df['plate'].astype(str).str.cat(train_df['well'],sep='/'),sep='/Plate') + '_s'+str(sample_num) + '_w'\n",
    "    train_df = train_df.drop(columns=['id_code','experiment','plate','well']).reindex(columns=['path','sirna'])\n",
    "    return train_df\n",
    "site1_train_df = generate_df(train_df)  \n",
    "site2_train_df = generate_df(train_df, sample_num=2)\n",
    "\n",
    "\n",
    "# proc_train_df = pd.concat([site1_train_df,site2_train_df],axis=0 )\\\n",
    "# .sample(frac = 1.0)\\\n",
    "# .reset_index()\\\n",
    "# .drop(\"index\",axis=1)\n",
    "proc_train_df = site1_train_df if SITE==1 else site2_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "Fq-2iKzBwa2V",
    "outputId": "7ca0733a-10d4-4f87-d725-4ce202967437"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HEPG2-01/Plate1/B03_s1_w</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HEPG2-01/Plate1/B04_s1_w</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HEPG2-01/Plate1/B05_s1_w</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HEPG2-01/Plate1/B06_s1_w</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HEPG2-01/Plate1/B07_s1_w</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>HEPG2-01/Plate1/B08_s1_w</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>HEPG2-01/Plate1/B09_s1_w</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>HEPG2-01/Plate1/B10_s1_w</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>HEPG2-01/Plate1/B11_s1_w</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>HEPG2-01/Plate1/B12_s1_w</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       path  sirna\n",
       "0  HEPG2-01/Plate1/B03_s1_w    513\n",
       "1  HEPG2-01/Plate1/B04_s1_w    840\n",
       "2  HEPG2-01/Plate1/B05_s1_w   1020\n",
       "3  HEPG2-01/Plate1/B06_s1_w    254\n",
       "4  HEPG2-01/Plate1/B07_s1_w    144\n",
       "5  HEPG2-01/Plate1/B08_s1_w    503\n",
       "6  HEPG2-01/Plate1/B09_s1_w    188\n",
       "7  HEPG2-01/Plate1/B10_s1_w    700\n",
       "8  HEPG2-01/Plate1/B11_s1_w   1100\n",
       "9  HEPG2-01/Plate1/B12_s1_w    611"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8XgaghTwa2X"
   },
   "source": [
    "Let's look at an example image. These images are 6-channel images, but the each of the six channels are saved as separate files. Here, I open just one channel of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "P61K3v_Vwa2X",
    "outputId": "018b1df3-0b97-4881-84ed-51020711dd62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(str(DATA/\"train/HEPG2-01/Plate1/B03_s1_w2.png\"))\n",
    "# plt.imshow(img)\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "# plt.imshow(gray_img)\n",
    "gray_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a07AWSdswa2a"
   },
   "source": [
    "In fastai, there is a modular data API that allows you to easily load images, add labels, split into train/valid, and add transforms. The base class for loading the images is an `ItemList`. For image classification tasks, the base class is `ImageList` which in turn subclasses the `ItemList` class. Since `ImageList` can only open 3-channel images, we will define a new `ImageList` class where we redefine the loading function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfDzD6Wuwa2a"
   },
   "outputs": [],
   "source": [
    "def open_rcic_image(fn):\n",
    "    images = []\n",
    "    for i in range(6):\n",
    "        file_name = fn+str(i+1)+'.png'\n",
    "        im = cv2.imread(file_name)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "        images.append(im)\n",
    "    image = np.dstack(images)\n",
    "    #print(pil2tensor(image, np.float32).shape)#.div_(255).shape)\n",
    "    return Image(pil2tensor(image, np.float32).div_(255))\n",
    "  \n",
    "class MultiChannelImageList(ImageList):\n",
    "    def open(self, fn):\n",
    "        return open_rcic_image(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_WqdWsiwa2c"
   },
   "source": [
    "As I subclassed the ImageList function I can load images with the `ImageList` function `.from_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4p_BcLTwa2e"
   },
   "outputs": [],
   "source": [
    "il = MultiChannelImageList.from_df(df=proc_train_df,path=DATA/'train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3mQg0A1wa2l"
   },
   "source": [
    "We have to redefine the following function to be able to view the image in the notebook. I view just the first 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVruUNW0wa2l"
   },
   "outputs": [],
   "source": [
    "def image2np(image:Tensor)->np.ndarray:\n",
    "    \"Convert from torch style `image` to numpy/matplotlib style.\"\n",
    "    res = image.cpu().permute(1,2,0).numpy()\n",
    "    if res.shape[2]==1:\n",
    "        return res[...,0]  \n",
    "    elif res.shape[2]>3:\n",
    "        #print(res.shape)\n",
    "        #print(res[...,:3].shape)\n",
    "        return res[...,:3]\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "vision.image.image2np = image2np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uR8wOHAXwa2r"
   },
   "source": [
    "Now let's view an example image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "colab_type": "code",
    "id": "4904GgsJwa2r",
    "outputId": "f4131f6f-5d84-42da-fb61-d8ba68a63b74"
   },
   "outputs": [],
   "source": [
    "# il[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RJelHuLwa2t"
   },
   "source": [
    "With the multi-channel `ImageList` defined, we can now create a DataBunch of the train images. Let's first create a stratified split of dataset and get the indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3Dlp01Bwa2u"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "#train_idx, val_idx = next(iter(StratifiedKFold(n_splits=int(1/0.035),random_state=42).split(proc_train_df, proc_train_df.sirna)))\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df,val_df = train_test_split(proc_train_df,test_size=0.035, stratify = proc_train_df.sirna, random_state=42)\n",
    "_proc_train_df = pd.concat([train_df,val_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diwrgp9ewa2w"
   },
   "source": [
    "Now we create the `DataBunch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXTb_YxZwa2w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data bunch\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating data bunch\")\n",
    "data = (MultiChannelImageList.from_df(df=_proc_train_df,path=DATA/'train/')\n",
    "        .split_by_idx(list(range(len(train_df),len(_proc_train_df))))\n",
    "        .label_from_df()\n",
    "        .transform(get_transforms(do_flip=True,flip_vert=True),size=SIZE)\n",
    "        .databunch(bs=BS,num_workers=4)\n",
    "        .normalize()\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xba28Znvwa2z"
   },
   "outputs": [],
   "source": [
    "# data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_mxelLONwa21"
   },
   "source": [
    "## Creating and Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RECFNRy3wa22"
   },
   "source": [
    "I will use a pretrained EfficientNet. There is code for other models thatt you can try but the EfficientNet seems to do the best. I have to now adjust the CNN arch to take in 6 channels as opposed to the usual 3 channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "jiawTWYgi9Ky",
    "outputId": "47872c63-45a6-4892-e328-b8ffcad88ad2"
   },
   "outputs": [],
   "source": [
    "# !pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XQpndYbjVkg"
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SITNC-7_wa22"
   },
   "outputs": [],
   "source": [
    "\"\"\"Inspired by https://github.com/wdhorton/protein-atlas-fastai/blob/master/resnet.py\"\"\"\n",
    "\n",
    "import torchvision\n",
    "RESNET_MODELS = {\n",
    "    18: torchvision.models.resnet18,\n",
    "    34: torchvision.models.resnet34,\n",
    "    50: torchvision.models.resnet50,\n",
    "    101: torchvision.models.resnet101,\n",
    "    152: torchvision.models.resnet152,\n",
    "}\n",
    "\n",
    "def resnet_multichannel(depth=50,pretrained=True,num_classes=1108,num_channels=6):\n",
    "        model = RESNET_MODELS[depth](pretrained=pretrained)\n",
    "        w = model.conv1.weight\n",
    "        model.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        model.conv1.weight = nn.Parameter(torch.stack([torch.mean(w, 1)]*num_channels, dim=1))\n",
    "        return model\n",
    "\n",
    "    \n",
    "DENSENET_MODELS = {\n",
    "    121: torchvision.models.densenet121,\n",
    "    161: torchvision.models.densenet161,\n",
    "    169: torchvision.models.densenet169,\n",
    "    201: torchvision.models.densenet201,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def densenet_multichannel(depth=121,pretrained=True,num_classes=1108,num_channels=6):\n",
    "    model = DENSENET_MODELS[depth](pretrained=pretrained)\n",
    "    \n",
    "    w = model.features.conv0.weight\n",
    "    model.features.conv0 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "    model.features.conv0.weight = nn.Parameter(torch.stack([torch.mean(w, 1)]*num_channels, dim=1))\n",
    "    \n",
    "    class dnNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.features = model.features\n",
    "            self.classifier = nn.Linear(model.classifier.weight.data.size(1), num_classes)\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):nn.init.kaiming_normal(m.weight.data)\n",
    "                elif isinstance(m, nn.BatchNorm2d):m.weight.data.fill_(1);m.bias.data.zero_()\n",
    "                elif isinstance(m, nn.Linear):m.bias.data.zero_()\n",
    "            \n",
    "        def forward(self,x):\n",
    "            features = self.features(x)\n",
    "            out = F.relu(features, inplace=True)\n",
    "            out = F.avg_pool2d(out, kernel_size=14, stride=1).view(features.size(0), -1)\n",
    "            out = self.classifier(out)\n",
    "            return out\n",
    "    dn_model = dnNet()\n",
    "    return dn_model\n",
    "        \n",
    "        \n",
    "#EFFICIENTNET_MODELS = {\n",
    "#    'b0': '../input/efficientnet-pytorch/efficientnet-b0-08094119.pth',\n",
    "#    'b1': '../input/efficientnet-pytorch/efficientnet-b1-dbc7070a.pth',\n",
    "#    'b2': '../input/efficientnet-pytorch/efficientnet-b2-27687264.pth',\n",
    "#    'b3': '../input/efficientnet-pytorch/efficientnet-b3-c8376fa2.pth',\n",
    "#    'b4': '../input/efficientnet-pytorch/efficientnet-b4-e116e8b3.pth',\n",
    "#    'b5': '../input/efficientnet-pytorch/efficientnet-b5-586e6cc6.pth'\n",
    "#}\n",
    "\n",
    "\n",
    "def efficientnet_multichannel(pretrained=True,name='b5',num_classes=1108,num_channels=6,image_size=SIZE):\n",
    "    model = EfficientNet.from_pretrained('efficientnet-'+name,num_classes=num_classes)\n",
    "    #model.load_state_dict(torch.load(EFFICIENTNET_MODELS[name]))\n",
    "    w = model._conv_stem.weight\n",
    "    #s = model._conv_stem.static_padding\n",
    "    model._conv_stem = utils.Conv2dStaticSamePadding(num_channels,32,kernel_size=(3, 3), stride=(2, 2), bias=False, image_size = image_size)\n",
    "    model._conv_stem.weight = nn.Parameter(torch.stack([torch.mean(w, 1)]*num_channels, dim=1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byAmg0Zle--u"
   },
   "outputs": [],
   "source": [
    "def resnet18(pretrained,num_channels=6):\n",
    "    return resnet_multichannel(depth=18,pretrained=pretrained,num_channels=num_channels)\n",
    "\n",
    "def _resnet_split(m): return (m[0][6],m[1])\n",
    "\n",
    "def densenet(name,pretrained=True,num_channels=6):\n",
    "    return densenet_multichannel(depth=int(name.replace(\"dn\",\"\")),pretrained=pretrained,num_channels=num_channels)\n",
    "  \n",
    "def _densenet_split(m:nn.Module): return (m[0][0][7],m[1])\n",
    "\n",
    "def efficientnetbn(name = \"b3\", pretrained=True,num_channels=6):\n",
    "    return efficientnet_multichannel(pretrained=pretrained,name=name,num_channels=num_channels)\n",
    "\n",
    "def getModel(name):\n",
    "    if name in list(\"b%s\"%(i) for i in range(6)):\n",
    "        return efficientnetbn(name = name)\n",
    "    elif name in [\"dn121\",\"dn169\",\"dn161\",\"dn201\"]:\n",
    "        return densenet(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "duo9Fd26wa2-"
   },
   "source": [
    "Let's create our Learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "XJvIjoGlwa3A",
    "outputId": "5c658594-a5de-43ca-c1ff-8ac4bbc07f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "from fastai.metrics import *\n",
    "print(\"Create model\")\n",
    "learn = Learner(data, getModel(MODEL_TYPE),metrics=[accuracy]).to_fp16()\n",
    "learn.path = Path('/data/rcic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WAhkRXkwwa3R"
   },
   "source": [
    "We will now unfreeze and train the entire model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD:\n",
    "    learn.load(LOAD_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "lHPKmKgLwa3S",
    "outputId": "71ecee97-0209-499b-8dd9-1bf6dd05045b"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "#learn.lr_find() #<-- uncomment to determine the learning rate (commented to reduce time)\n",
    "#learn.recorder.plot(suggestion=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "OBwtrSGbwa3V",
    "outputId": "83e5e437-8957-499e-ba4f-ee6c75d5c731"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(18,1e-3,callbacks=[SaveModelCallback(learn, every='epoch', monitor='accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "apFsHYKXwa3X",
    "outputId": "cc4b5035-fea2-4a54-c022-6456e4dfaf24"
   },
   "outputs": [],
   "source": [
    "# learn.recorder.plot_losses()\n",
    "# learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITSX3vH0wa3Z"
   },
   "outputs": [],
   "source": [
    "learn.save(SAVE_NAME)\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GA4EcIQIwa3b"
   },
   "source": [
    "## Inference and Submission Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C47mcIFTwa3c"
   },
   "source": [
    "Let's now load our test csv and process the DataFrame like we did for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISLuc-u2wa3d"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(DATA/'test.csv')\n",
    "proc_test_df = generate_df(test_df.copy(),sample_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nkcB9CxXwa3g"
   },
   "source": [
    "We add the data to our DataBunch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FidBxNo3wa3h"
   },
   "outputs": [],
   "source": [
    "data_test = MultiChannelImageList.from_df(df=proc_test_df,path=DATA/'test/')\n",
    "learn.data.add_test(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBHsXyj9wa3l"
   },
   "source": [
    "Now we can get out predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubEraC8xwa3m"
   },
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OaYyqaClwa3t"
   },
   "outputs": [],
   "source": [
    "preds_ = preds.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UWz4Pmnwa3x"
   },
   "outputs": [],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txbsG6yDwa33"
   },
   "source": [
    "Let's open the sample submission file and load it with our predictions to create a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qlw2WtI5wa33"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(DATA/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzV7ochrwa36"
   },
   "outputs": [],
   "source": [
    "submission_df.sirna = preds_.numpy().astype(int)\n",
    "print(submission_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCSGb2RRwa39"
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "rcic_fastai_starter.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
