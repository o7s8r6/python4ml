{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uggxhoHpwa2K"
   },
   "source": [
    "# Recursion Cellular Image Classification - fastai starter\n",
    "\n",
    "Thanks greatly to [this kaggle kernel](https://www.kaggle.com/kernels/scriptcontent/20557703/download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m67AVgPxwa2L"
   },
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92p63IbDwa2L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mJopzu_evYF"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAHj2Ulawa2R"
   },
   "source": [
    "## Loading and formatting data\n",
    "\n",
    "Here I will load the csv into the DataFrame, and create a column in the DataFrame with the path to the corresponding image (`generate_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"/mnt/disk4/cell/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "VI6_C0cVwa2R",
    "outputId": "64557492-946d-4cd1-9a7a-087edc91886d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>experiment</th>\n",
       "      <th>plate</th>\n",
       "      <th>well</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-01_1_B03</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B03</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-01_1_B04</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B04</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-01_1_B05</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B05</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-01_1_B06</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B06</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-01_1_B07</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B07</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEPG2-01_1_B08</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B08</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HEPG2-01_1_B09</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B09</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HEPG2-01_1_B10</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B10</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HEPG2-01_1_B11</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B11</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HEPG2-01_1_B12</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code experiment  plate well  sirna\n",
       "0  HEPG2-01_1_B03   HEPG2-01      1  B03    513\n",
       "1  HEPG2-01_1_B04   HEPG2-01      1  B04    840\n",
       "2  HEPG2-01_1_B05   HEPG2-01      1  B05   1020\n",
       "3  HEPG2-01_1_B06   HEPG2-01      1  B06    254\n",
       "4  HEPG2-01_1_B07   HEPG2-01      1  B07    144\n",
       "5  HEPG2-01_1_B08   HEPG2-01      1  B08    503\n",
       "6  HEPG2-01_1_B09   HEPG2-01      1  B09    188\n",
       "7  HEPG2-01_1_B10   HEPG2-01      1  B10    700\n",
       "8  HEPG2-01_1_B11   HEPG2-01      1  B11   1100\n",
       "9  HEPG2-01_1_B12   HEPG2-01      1  B12    611"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(DATA/'train.csv')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeEIRS-iwa2T"
   },
   "outputs": [],
   "source": [
    "def generate_df(train_df,sample_num=1):\n",
    "    train_df['path'] = train_df['experiment'].str.cat(train_df['plate'].astype(str).str.cat(train_df['well'],sep='/'),sep='/Plate') + '_s'+str(sample_num) + '_w'\n",
    "    train_df = train_df.drop(columns=['id_code','experiment','plate','well']).reindex(columns=['path','sirna'])\n",
    "    return train_df\n",
    "site1_train_df = generate_df(train_df)  \n",
    "site2_train_df = generate_df(train_df, sample_num=2)\n",
    "\n",
    "proc_train_df = pd.concat([site1_train_df,site2_train_df],axis=0 )\\\n",
    ".sample(frac = 1.0)\\\n",
    ".reset_index()\\\n",
    ".drop(\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "Fq-2iKzBwa2V",
    "outputId": "7ca0733a-10d4-4f87-d725-4ce202967437"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HUVEC-15/Plate4/G13_s2_w</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RPE-04/Plate4/B19_s1_w</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-05/Plate3/H14_s1_w</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RPE-04/Plate4/F05_s2_w</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HUVEC-14/Plate2/B13_s2_w</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RPE-01/Plate1/B03_s1_w</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HUVEC-13/Plate1/K19_s2_w</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U2OS-02/Plate2/B17_s2_w</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HUVEC-08/Plate1/O13_s2_w</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HUVEC-02/Plate1/B22_s2_w</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       path  sirna\n",
       "0  HUVEC-15/Plate4/G13_s2_w    981\n",
       "1    RPE-04/Plate4/B19_s1_w    954\n",
       "2  HEPG2-05/Plate3/H14_s1_w    757\n",
       "3    RPE-04/Plate4/F05_s2_w    803\n",
       "4  HUVEC-14/Plate2/B13_s2_w   1004\n",
       "5    RPE-01/Plate1/B03_s1_w   1084\n",
       "6  HUVEC-13/Plate1/K19_s2_w    678\n",
       "7   U2OS-02/Plate2/B17_s2_w    357\n",
       "8  HUVEC-08/Plate1/O13_s2_w   1100\n",
       "9  HUVEC-02/Plate1/B22_s2_w    301"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8XgaghTwa2X"
   },
   "source": [
    "Let's look at an example image. These images are 6-channel images, but the each of the six channels are saved as separate files. Here, I open just one channel of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "P61K3v_Vwa2X",
    "outputId": "018b1df3-0b97-4881-84ed-51020711dd62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(str(DATA/\"train/HEPG2-01/Plate1/B03_s1_w2.png\"))\n",
    "# plt.imshow(img)\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "# plt.imshow(gray_img)\n",
    "gray_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a07AWSdswa2a"
   },
   "source": [
    "In fastai, there is a modular data API that allows you to easily load images, add labels, split into train/valid, and add transforms. The base class for loading the images is an `ItemList`. For image classification tasks, the base class is `ImageList` which in turn subclasses the `ItemList` class. Since `ImageList` can only open 3-channel images, we will define a new `ImageList` class where we redefine the loading function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfDzD6Wuwa2a"
   },
   "outputs": [],
   "source": [
    "def open_rcic_image(fn):\n",
    "    images = []\n",
    "    for i in range(6):\n",
    "        file_name = fn+str(i+1)+'.png'\n",
    "        im = cv2.imread(file_name)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "        images.append(im)\n",
    "    image = np.dstack(images)\n",
    "    #print(pil2tensor(image, np.float32).shape)#.div_(255).shape)\n",
    "    return Image(pil2tensor(image, np.float32).div_(255))\n",
    "  \n",
    "class MultiChannelImageList(ImageList):\n",
    "    def open(self, fn):\n",
    "        return open_rcic_image(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_WqdWsiwa2c"
   },
   "source": [
    "As I subclassed the ImageList function I can load images with the `ImageList` function `.from_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4p_BcLTwa2e"
   },
   "outputs": [],
   "source": [
    "il = MultiChannelImageList.from_df(df=proc_train_df,path=DATA/'train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3mQg0A1wa2l"
   },
   "source": [
    "We have to redefine the following function to be able to view the image in the notebook. I view just the first 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVruUNW0wa2l"
   },
   "outputs": [],
   "source": [
    "def image2np(image:Tensor)->np.ndarray:\n",
    "    \"Convert from torch style `image` to numpy/matplotlib style.\"\n",
    "    res = image.cpu().permute(1,2,0).numpy()\n",
    "    if res.shape[2]==1:\n",
    "        return res[...,0]  \n",
    "    elif res.shape[2]>3:\n",
    "        #print(res.shape)\n",
    "        #print(res[...,:3].shape)\n",
    "        return res[...,:3]\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "vision.image.image2np = image2np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uR8wOHAXwa2r"
   },
   "source": [
    "Now let's view an example image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "colab_type": "code",
    "id": "4904GgsJwa2r",
    "outputId": "f4131f6f-5d84-42da-fb61-d8ba68a63b74"
   },
   "outputs": [],
   "source": [
    "# il[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RJelHuLwa2t"
   },
   "source": [
    "With the multi-channel `ImageList` defined, we can now create a DataBunch of the train images. Let's first create a stratified split of dataset and get the indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3Dlp01Bwa2u"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "#train_idx, val_idx = next(iter(StratifiedKFold(n_splits=int(1/0.035),random_state=42).split(proc_train_df, proc_train_df.sirna)))\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df,val_df = train_test_split(proc_train_df,test_size=0.035, stratify = proc_train_df.sirna, random_state=42)\n",
    "_proc_train_df = pd.concat([train_df,val_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diwrgp9ewa2w"
   },
   "source": [
    "Now we create the `DataBunch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXTb_YxZwa2w"
   },
   "outputs": [],
   "source": [
    "data = (MultiChannelImageList.from_df(df=_proc_train_df,path=DATA/'train/')\n",
    "        .split_by_idx(list(range(len(train_df),len(_proc_train_df))))\n",
    "        .label_from_df()\n",
    "        .transform(get_transforms(),size=SIZE)\n",
    "        .databunch(bs=16,num_workers=4)\n",
    "        .normalize()\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xba28Znvwa2z"
   },
   "outputs": [],
   "source": [
    "# data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_mxelLONwa21"
   },
   "source": [
    "## Creating and Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RECFNRy3wa22"
   },
   "source": [
    "I will use a pretrained EfficientNet. There is code for other models thatt you can try but the EfficientNet seems to do the best. I have to now adjust the CNN arch to take in 6 channels as opposed to the usual 3 channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "jiawTWYgi9Ky",
    "outputId": "47872c63-45a6-4892-e328-b8ffcad88ad2"
   },
   "outputs": [],
   "source": [
    "# !pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XQpndYbjVkg"
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SITNC-7_wa22"
   },
   "outputs": [],
   "source": [
    "\"\"\"Inspired by https://github.com/wdhorton/protein-atlas-fastai/blob/master/resnet.py\"\"\"\n",
    "\n",
    "import torchvision\n",
    "RESNET_MODELS = {\n",
    "    18: torchvision.models.resnet18,\n",
    "    34: torchvision.models.resnet34,\n",
    "    50: torchvision.models.resnet50,\n",
    "    101: torchvision.models.resnet101,\n",
    "    152: torchvision.models.resnet152,\n",
    "}\n",
    "\n",
    "def resnet_multichannel(depth=50,pretrained=True,num_classes=1108,num_channels=6):\n",
    "        model = RESNET_MODELS[depth](pretrained=pretrained)\n",
    "        w = model.conv1.weight\n",
    "        model.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        model.conv1.weight = nn.Parameter(torch.stack([torch.mean(w, 1)]*num_channels, dim=1))\n",
    "        return model\n",
    "\n",
    "    \n",
    "DENSENET_MODELS = {\n",
    "    121: torchvision.models.densenet121,\n",
    "    161: torchvision.models.densenet161,\n",
    "    169: torchvision.models.densenet169,\n",
    "    201: torchvision.models.densenet201,\n",
    "}\n",
    "\n",
    "def densenet_multichannel(depth=121,pretrained=True,num_classes=1108,num_channels=6):\n",
    "        model = DENSENET_MODELS[depth](pretrained=pretrained)\n",
    "        w = model.features.conv0.weight\n",
    "        model.features.conv0 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        model.features.conv0.weight = nn.Parameter(torch.stack([torch.mean(w, 1)]*num_channels, dim=1))\n",
    "        return model\n",
    "        \n",
    "        \n",
    "#EFFICIENTNET_MODELS = {\n",
    "#    'b0': '../input/efficientnet-pytorch/efficientnet-b0-08094119.pth',\n",
    "#    'b1': '../input/efficientnet-pytorch/efficientnet-b1-dbc7070a.pth',\n",
    "#    'b2': '../input/efficientnet-pytorch/efficientnet-b2-27687264.pth',\n",
    "#    'b3': '../input/efficientnet-pytorch/efficientnet-b3-c8376fa2.pth',\n",
    "#    'b4': '../input/efficientnet-pytorch/efficientnet-b4-e116e8b3.pth',\n",
    "#    'b5': '../input/efficientnet-pytorch/efficientnet-b5-586e6cc6.pth'\n",
    "#}\n",
    "\n",
    "\n",
    "def efficientnet_multichannel(pretrained=True,name='b3',num_classes=1108,num_channels=6,image_size=SIZE):\n",
    "    model = EfficientNet.from_pretrained('efficientnet-'+name,num_classes=num_classes)\n",
    "    #model.load_state_dict(torch.load(EFFICIENTNET_MODELS[name]))\n",
    "    w = model._conv_stem.weight\n",
    "    #s = model._conv_stem.static_padding\n",
    "    model._conv_stem = utils.Conv2dStaticSamePadding(num_channels,32,kernel_size=(3, 3), stride=(2, 2), bias=False, image_size = image_size)\n",
    "    model._conv_stem.weight = nn.Parameter(torch.stack([torch.mean(w, 1)]*num_channels, dim=1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byAmg0Zle--u"
   },
   "outputs": [],
   "source": [
    "def resnet18(pretrained,num_channels=6):\n",
    "    return resnet_multichannel(depth=18,pretrained=pretrained,num_channels=num_channels)\n",
    "\n",
    "def _resnet_split(m): return (m[0][6],m[1])\n",
    "\n",
    "def densenet161(pretrained,num_channels=6):\n",
    "    return densenet_multichannel(depth=161,pretrained=pretrained,num_channels=num_channels)\n",
    "  \n",
    "def _densenet_split(m:nn.Module): return (m[0][0][7],m[1])\n",
    "\n",
    "def efficientnetbn(pretrained=True,num_channels=6):\n",
    "    return efficientnet_multichannel(pretrained=pretrained,name='b3',num_channels=num_channels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "duo9Fd26wa2-"
   },
   "source": [
    "Let's create our Learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "XJvIjoGlwa3A",
    "outputId": "5c658594-a5de-43ca-c1ff-8ac4bbc07f8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://storage.googleapis.com/public-models/efficientnet/efficientnet-b3-5fb5a3c3.pth\" to /home/hadoop/.cache/torch/checkpoints/efficientnet-b3-5fb5a3c3.pth\n",
      "100%|██████████| 47.1M/47.1M [00:03<00:00, 15.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "from fastai.metrics import *\n",
    "learn = Learner(data, efficientnetbn(),metrics=[accuracy]).to_fp16()\n",
    "learn.path = Path('/data/rcic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WAhkRXkwwa3R"
   },
   "source": [
    "We will now unfreeze and train the entire model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"effv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "lHPKmKgLwa3S",
    "outputId": "71ecee97-0209-499b-8dd9-1bf6dd05045b"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "#learn.lr_find() #<-- uncomment to determine the learning rate (commented to reduce time)\n",
    "#learn.recorder.plot(suggestion=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "OBwtrSGbwa3V",
    "outputId": "83e5e437-8957-499e-ba4f-ee6c75d5c731"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(18,1e-3,callbacks=[SaveModelCallback(learn, every='epoch', monitor='accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "apFsHYKXwa3X",
    "outputId": "cc4b5035-fea2-4a54-c022-6456e4dfaf24"
   },
   "outputs": [],
   "source": [
    "# learn.recorder.plot_losses()\n",
    "# learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITSX3vH0wa3Z"
   },
   "outputs": [],
   "source": [
    "learn.save('effv5end')\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GA4EcIQIwa3b"
   },
   "source": [
    "## Inference and Submission Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C47mcIFTwa3c"
   },
   "source": [
    "Let's now load our test csv and process the DataFrame like we did for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISLuc-u2wa3d"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(DATA/'test.csv')\n",
    "proc_test_df = generate_df(test_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nkcB9CxXwa3g"
   },
   "source": [
    "We add the data to our DataBunch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FidBxNo3wa3h"
   },
   "outputs": [],
   "source": [
    "data_test = MultiChannelImageList.from_df(df=proc_test_df,path=DATA/'test/')\n",
    "learn.data.add_test(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBHsXyj9wa3l"
   },
   "source": [
    "Now we can get out predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubEraC8xwa3m"
   },
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OaYyqaClwa3t"
   },
   "outputs": [],
   "source": [
    "preds_ = preds.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UWz4Pmnwa3x"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>experiment</th>\n",
       "      <th>plate</th>\n",
       "      <th>well</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-08_1_B03</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-08_1_B04</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-08_1_B05</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-08_1_B06</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-08_1_B07</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEPG2-08_1_B08</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HEPG2-08_1_B09</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HEPG2-08_1_B10</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HEPG2-08_1_B11</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HEPG2-08_1_B12</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code experiment  plate well\n",
       "0  HEPG2-08_1_B03   HEPG2-08      1  B03\n",
       "1  HEPG2-08_1_B04   HEPG2-08      1  B04\n",
       "2  HEPG2-08_1_B05   HEPG2-08      1  B05\n",
       "3  HEPG2-08_1_B06   HEPG2-08      1  B06\n",
       "4  HEPG2-08_1_B07   HEPG2-08      1  B07\n",
       "5  HEPG2-08_1_B08   HEPG2-08      1  B08\n",
       "6  HEPG2-08_1_B09   HEPG2-08      1  B09\n",
       "7  HEPG2-08_1_B10   HEPG2-08      1  B10\n",
       "8  HEPG2-08_1_B11   HEPG2-08      1  B11\n",
       "9  HEPG2-08_1_B12   HEPG2-08      1  B12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txbsG6yDwa33"
   },
   "source": [
    "Let's open the sample submission file and load it with our predictions to create a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qlw2WtI5wa33"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(DATA/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzV7ochrwa36"
   },
   "outputs": [],
   "source": [
    "submission_df.sirna = preds_.numpy().astype(int)\n",
    "print(submission_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCSGb2RRwa39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DTx-gbx7wa3_"
   },
   "source": [
    "That's it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BvrnXpFkwa4A"
   },
   "source": [
    "## Future work:\n",
    "\n",
    "This is only a simple baseline. There are many different things we can change:\n",
    "* Use both sites (right now I only use site 1)\n",
    "* Model architecture\n",
    "* Train multiple classifiers for different cell types\n",
    "* **Metric learning** - This will be the key to successful submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "rcic_fastai_starter.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
