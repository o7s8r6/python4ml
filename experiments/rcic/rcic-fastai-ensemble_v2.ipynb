{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uggxhoHpwa2K"
   },
   "source": [
    "# Recursion Cellular Image Classification - fastai starter\n",
    "\n",
    "* Thanks greatly to [this kaggle kernel](https://www.kaggle.com/kernels/scriptcontent/20557703/download)\n",
    "* This is the ensemble version of notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m67AVgPxwa2L"
   },
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92p63IbDwa2L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mJopzu_evYF"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAHj2Ulawa2R"
   },
   "source": [
    "## Loading and formatting data\n",
    "\n",
    "Here I will load the csv into the DataFrame, and create a column in the DataFrame with the path to the corresponding image (`generate_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"/mnt/disk4/cell/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "VI6_C0cVwa2R",
    "outputId": "64557492-946d-4cd1-9a7a-087edc91886d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>experiment</th>\n",
       "      <th>plate</th>\n",
       "      <th>well</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-01_1_B03</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B03</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-01_1_B04</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B04</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-01_1_B05</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B05</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-01_1_B06</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B06</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-01_1_B07</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B07</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEPG2-01_1_B08</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B08</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HEPG2-01_1_B09</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B09</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HEPG2-01_1_B10</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B10</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HEPG2-01_1_B11</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B11</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HEPG2-01_1_B12</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code experiment  plate well  sirna\n",
       "0  HEPG2-01_1_B03   HEPG2-01      1  B03    513\n",
       "1  HEPG2-01_1_B04   HEPG2-01      1  B04    840\n",
       "2  HEPG2-01_1_B05   HEPG2-01      1  B05   1020\n",
       "3  HEPG2-01_1_B06   HEPG2-01      1  B06    254\n",
       "4  HEPG2-01_1_B07   HEPG2-01      1  B07    144\n",
       "5  HEPG2-01_1_B08   HEPG2-01      1  B08    503\n",
       "6  HEPG2-01_1_B09   HEPG2-01      1  B09    188\n",
       "7  HEPG2-01_1_B10   HEPG2-01      1  B10    700\n",
       "8  HEPG2-01_1_B11   HEPG2-01      1  B11   1100\n",
       "9  HEPG2-01_1_B12   HEPG2-01      1  B12    611"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(DATA/'train.csv')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeEIRS-iwa2T"
   },
   "outputs": [],
   "source": [
    "def generate_df(train_df,sample_num=1):\n",
    "    train_df['path'] = train_df['experiment'].str.cat(train_df['plate'].astype(str).str.cat(train_df['well'],sep='/'),sep='/Plate') + '_s'+str(sample_num) + '_w'\n",
    "    train_df = train_df.drop(columns=['id_code','experiment','plate','well']).reindex(columns=['path','sirna'])\n",
    "    return train_df\n",
    "site1_train_df = generate_df(train_df)  \n",
    "site2_train_df = generate_df(train_df, sample_num=2)\n",
    "\n",
    "proc_train_df = pd.concat([site1_train_df,site2_train_df],axis=0 )\\\n",
    ".sample(frac = 1.0)\\\n",
    ".reset_index()\\\n",
    ".drop(\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8XgaghTwa2X"
   },
   "source": [
    "Let's look at an example image. These images are 6-channel images, but the each of the six channels are saved as separate files. Here, I open just one channel of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "Fq-2iKzBwa2V",
    "outputId": "7ca0733a-10d4-4f87-d725-4ce202967437"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HUVEC-15/Plate4/G13_s2_w</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RPE-04/Plate4/B19_s1_w</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-05/Plate3/H14_s1_w</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RPE-04/Plate4/F05_s2_w</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HUVEC-14/Plate2/B13_s2_w</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RPE-01/Plate1/B03_s1_w</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HUVEC-13/Plate1/K19_s2_w</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U2OS-02/Plate2/B17_s2_w</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HUVEC-08/Plate1/O13_s2_w</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HUVEC-02/Plate1/B22_s2_w</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       path  sirna\n",
       "0  HUVEC-15/Plate4/G13_s2_w    981\n",
       "1    RPE-04/Plate4/B19_s1_w    954\n",
       "2  HEPG2-05/Plate3/H14_s1_w    757\n",
       "3    RPE-04/Plate4/F05_s2_w    803\n",
       "4  HUVEC-14/Plate2/B13_s2_w   1004\n",
       "5    RPE-01/Plate1/B03_s1_w   1084\n",
       "6  HUVEC-13/Plate1/K19_s2_w    678\n",
       "7   U2OS-02/Plate2/B17_s2_w    357\n",
       "8  HUVEC-08/Plate1/O13_s2_w   1100\n",
       "9  HUVEC-02/Plate1/B22_s2_w    301"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "P61K3v_Vwa2X",
    "outputId": "018b1df3-0b97-4881-84ed-51020711dd62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(str(DATA/\"train/HEPG2-01/Plate1/B03_s1_w2.png\"))\n",
    "# plt.imshow(img)\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "# plt.imshow(gray_img)\n",
    "gray_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a07AWSdswa2a"
   },
   "source": [
    "In fastai, there is a modular data API that allows you to easily load images, add labels, split into train/valid, and add transforms. The base class for loading the images is an `ItemList`. For image classification tasks, the base class is `ImageList` which in turn subclasses the `ItemList` class. Since `ImageList` can only open 3-channel images, we will define a new `ImageList` class where we redefine the loading function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfDzD6Wuwa2a"
   },
   "outputs": [],
   "source": [
    "def open_rcic_image(fn):\n",
    "    images = []\n",
    "    for i in range(6):\n",
    "        file_name = fn+str(i+1)+'.png'\n",
    "        im = cv2.imread(file_name)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "        images.append(im)\n",
    "    image = np.dstack(images)\n",
    "    #print(pil2tensor(image, np.float32).shape)#.div_(255).shape)\n",
    "    return Image(pil2tensor(image, np.float32).div_(255))\n",
    "  \n",
    "class MultiChannelImageList(ImageList):\n",
    "    def open(self, fn):\n",
    "        return open_rcic_image(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_WqdWsiwa2c"
   },
   "source": [
    "As I subclassed the ImageList function I can load images with the `ImageList` function `.from_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4p_BcLTwa2e"
   },
   "outputs": [],
   "source": [
    "il = MultiChannelImageList.from_df(df=proc_train_df,path=DATA/'train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3mQg0A1wa2l"
   },
   "source": [
    "We have to redefine the following function to be able to view the image in the notebook. I view just the first 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVruUNW0wa2l"
   },
   "outputs": [],
   "source": [
    "def image2np(image:Tensor)->np.ndarray:\n",
    "    \"Convert from torch style `image` to numpy/matplotlib style.\"\n",
    "    res = image.cpu().permute(1,2,0).numpy()\n",
    "    if res.shape[2]==1:\n",
    "        return res[...,0]  \n",
    "    elif res.shape[2]>3:\n",
    "        #print(res.shape)\n",
    "        #print(res[...,:3].shape)\n",
    "        return res[...,:3]\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "vision.image.image2np = image2np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uR8wOHAXwa2r"
   },
   "source": [
    "Now let's view an example image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "colab_type": "code",
    "id": "4904GgsJwa2r",
    "outputId": "f4131f6f-5d84-42da-fb61-d8ba68a63b74"
   },
   "outputs": [],
   "source": [
    "# il[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RJelHuLwa2t"
   },
   "source": [
    "With the multi-channel `ImageList` defined, we can now create a DataBunch of the train images. Let's first create a stratified split of dataset and get the indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3Dlp01Bwa2u"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "#train_idx, val_idx = next(iter(StratifiedKFold(n_splits=int(1/0.035),random_state=42).split(proc_train_df, proc_train_df.sirna)))\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df,val_df = train_test_split(proc_train_df,test_size=0.035, stratify = proc_train_df.sirna, random_state=42)\n",
    "_proc_train_df = pd.concat([train_df,val_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diwrgp9ewa2w"
   },
   "source": [
    "Now we create the `DataBunch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xba28Znvwa2z"
   },
   "outputs": [],
   "source": [
    "# data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_mxelLONwa21"
   },
   "source": [
    "## Creating and Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RECFNRy3wa22"
   },
   "source": [
    "I will use a pretrained EfficientNet. There is code for other models thatt you can try but the EfficientNet seems to do the best. I have to now adjust the CNN arch to take in 6 channels as opposed to the usual 3 channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "jiawTWYgi9Ky",
    "outputId": "47872c63-45a6-4892-e328-b8ffcad88ad2"
   },
   "outputs": [],
   "source": [
    "# !pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XQpndYbjVkg"
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SITNC-7_wa22"
   },
   "outputs": [],
   "source": [
    "\"\"\"Inspired by https://github.com/wdhorton/protein-atlas-fastai/blob/master/resnet.py\"\"\"\n",
    "\n",
    "import torchvision\n",
    "RESNET_MODELS = {\n",
    "    18: torchvision.models.resnet18,\n",
    "    34: torchvision.models.resnet34,\n",
    "    50: torchvision.models.resnet50,\n",
    "    101: torchvision.models.resnet101,\n",
    "    152: torchvision.models.resnet152,\n",
    "}\n",
    "\n",
    "def resnet_multichannel(depth=50,pretrained=True,num_classes=1108,num_channels=6):\n",
    "        model = RESNET_MODELS[depth](pretrained=pretrained)\n",
    "        w = model.conv1.weight\n",
    "        model.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        model.conv1.weight = nn.Parameter(torch.stack([torch.mean(w, 1)]*num_channels, dim=1))\n",
    "        return model\n",
    "\n",
    "    \n",
    "DENSENET_MODELS = {\n",
    "    121: torchvision.models.densenet121,\n",
    "    161: torchvision.models.densenet161,\n",
    "    169: torchvision.models.densenet169,\n",
    "    201: torchvision.models.densenet201,\n",
    "}\n",
    "\n",
    "def densenet_multichannel(depth=121,pretrained=True,num_classes=1108,num_channels=6):\n",
    "        model = DENSENET_MODELS[depth](pretrained=pretrained)\n",
    "        w = model.features.conv0.weight\n",
    "        model.features.conv0 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        model.features.conv0.weight = nn.Parameter(torch.stack([torch.mean(w, 1)]*num_channels, dim=1))\n",
    "        return model\n",
    "\n",
    "\n",
    "def efficientnet_multichannel(pretrained=True,name='b3',num_classes=1108,num_channels=6,image_size=360):\n",
    "    model = EfficientNet.from_pretrained('efficientnet-'+name,num_classes=num_classes)\n",
    "    #model.load_state_dict(torch.load(EFFICIENTNET_MODELS[name]))\n",
    "    w = model._conv_stem.weight\n",
    "    #s = model._conv_stem.static_padding\n",
    "    model._conv_stem = utils.Conv2dStaticSamePadding(num_channels,32,kernel_size=(3, 3), stride=(2, 2), bias=False, image_size = image_size)\n",
    "    model._conv_stem.weight = nn.Parameter(torch.stack([torch.mean(w, 1)]*num_channels, dim=1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byAmg0Zle--u"
   },
   "outputs": [],
   "source": [
    "def resnet18(pretrained,num_channels=6):\n",
    "    return resnet_multichannel(depth=18,pretrained=pretrained,num_channels=num_channels)\n",
    "\n",
    "def _resnet_split(m): return (m[0][6],m[1])\n",
    "\n",
    "def densenet161(pretrained,num_channels=6):\n",
    "    return densenet_multichannel(depth=161,pretrained=pretrained,num_channels=num_channels)\n",
    "  \n",
    "def _densenet_split(m:nn.Module): return (m[0][0][7],m[1])\n",
    "\n",
    "def efficientnetbn(name, sz, pretrained=True,num_channels=6):\n",
    "    return efficientnet_multichannel(pretrained=pretrained,name=name, num_channels=num_channels, image_size = sz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GA4EcIQIwa3b"
   },
   "source": [
    "## Inference and Submission Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C47mcIFTwa3c"
   },
   "source": [
    "Let's now load our test csv and process the DataFrame like we did for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISLuc-u2wa3d"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(DATA/'test.csv')\n",
    "site1_test_df = generate_df(test_df.copy())\n",
    "site2_test_df = generate_df(test_df.copy(),sample_num=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction on a single model/ with single site test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p /data/rcic/saved_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache for predicting, if model is the same, args are the same:\n",
    "#     using the saved prediction\n",
    "PREDS = Path(\"/data/rcic/saved_preds\")\n",
    "def predCache(f):\n",
    "    \"\"\"\n",
    "    prediction cache decorator\n",
    "    \"\"\"\n",
    "    def func(**kwargs):\n",
    "        saved_fn = \"%s_site-%s.tsr\"%(kwargs[\"load\"].split(\".\")[0],kwargs[\"site\"])\n",
    "        save_path = str(PREDS/saved_fn)\n",
    "        if os.path.exists(save_path):\n",
    "            print(\"loading from cache: %s\"%(save_path))\n",
    "            return torch.load(save_path)\n",
    "        else:\n",
    "            pred = f(**kwargs)\n",
    "            torch.save(pred, save_path)\n",
    "            print(\"save to cache: %s\"%(save_path))\n",
    "            return pred\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FidBxNo3wa3h"
   },
   "outputs": [],
   "source": [
    "@predCache\n",
    "def getPred(name,sz,bs,load,site):\n",
    "    \"\"\"\n",
    "    get prediction for 2 sites using a pretrained model\n",
    "    name: str, in 'b0','b1','b2','b3'...,'b5'\n",
    "    site: 1 or 2\n",
    "    \"\"\"\n",
    "    site_test_df=site1_test_df if site==1 else site2_test_df\n",
    "    data_test = MultiChannelImageList.from_df(df = site_test_df,path=DATA/'test/')\n",
    "    data = (MultiChannelImageList.from_df(df=_proc_train_df,path=DATA/'train/')\n",
    "        .split_by_idx(list(range(len(train_df),len(_proc_train_df))))\n",
    "        .label_from_df()\n",
    "        .transform(get_transforms(),size=sz)\n",
    "        .databunch(bs=bs,num_workers=4)\n",
    "        .normalize()\n",
    "       )\n",
    "    learn = Learner(data, efficientnetbn(name,sz),metrics=[accuracy]).to_fp16()\n",
    "    learn.path = Path(\"./ensemble\")\n",
    "    learn.load(load)\n",
    "    learn.data.add_test(data_test)\n",
    "    preds, _ = learn.get_preds(DatasetType.Test)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(*args):\n",
    "    preds = list(args)\n",
    "    preds_len = len(preds)\n",
    "    preds_idx = (sum(preds)/preds_len).argmax(dim=-1)\n",
    "    return preds_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tensors = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to cache: /data/rcic/saved_preds/rcic-b3-s320-bs16-s2-e1_site-2.tsr\n",
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1110' class='' max='1244', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      89.23% [1110/1244 04:12<00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_tensors.append(getPred(name = \"b0\",sz = 256, bs = 64,load = \"rcic-b0-sz256-bs64-s12\", site = 1)) #0.272\n",
    "\n",
    "pred_tensors.append(getPred(name = \"b0\",sz = 256, bs = 64,load = \"rcic-b0-sz256-bs64-s12\", site = 2))\n",
    "\n",
    "pred_tensors.append(getPred(name = \"b3\",sz = 320, bs = 16,load = \"rcic-b3-s320-bs16-s12\", site = 1)) # 0.378\n",
    "\n",
    "pred_tensors.append(getPred(name = \"b3\",sz = 320, bs = 16,load = \"rcic-b3-s320-bs16-s2-e1\", site = 2)) # 0.329\n",
    "\n",
    "pred_tensors.append(getPred(name = \"b3\",sz = 320, bs = 16,load = \"rcic-b3-s320-bs16-s2-e_end\", site = 2)) # 0.390\n",
    "\n",
    "pred_tensors.append(getPred(name = \"b4\",sz = 380, bs = 16,load = \"rcic-b4-sz380-bs64-s1\", site = 1)) # 0.325\n",
    "\n",
    "pred_tensors.append(getPred(name = \"b4\",sz = 380, bs = 16,load = \"rcic-b4-sz380-bs36-s2\", site = 2)) # 0.326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ensemble(*pred_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txbsG6yDwa33"
   },
   "source": [
    "Let's open the sample submission file and load it with our predictions to create a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qlw2WtI5wa33"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(DATA/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzV7ochrwa36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id_code  sirna\n",
      "0  HEPG2-08_1_B03    855\n",
      "1  HEPG2-08_1_B04    796\n",
      "2  HEPG2-08_1_B05     19\n",
      "3  HEPG2-08_1_B06     65\n",
      "4  HEPG2-08_1_B07    823\n"
     ]
    }
   ],
   "source": [
    "submission_df.sirna = preds.numpy().astype(int)\n",
    "print(submission_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCSGb2RRwa39"
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "rcic_fastai_starter.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
